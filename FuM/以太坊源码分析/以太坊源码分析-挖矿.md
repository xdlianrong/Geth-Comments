# ä»¥å¤ªåŠæºç åˆ†æ-æŒ–çŸ¿

+ åœ¨æºç ç›®å½•ä¸­ï¼Œ`consensus`æä¾›äº†ä»¥å¤ªåŠçš„ä¸€äº›å…±è¯†ç®—æ³•ï¼Œ`miner`æä¾›ä»¥å¤ªåŠçš„åŒºå—åˆ›å»ºå’ŒæŒ–çŸ¿ã€‚
+ **æŒ–çŸ¿(`mine`)**æ˜¯æŒ‡çŸ¿å·¥èŠ‚ç‚¹äº’ç›¸ç«äº‰ç”Ÿæˆæ–°åŒºå—ä»¥å†™å…¥æ•´ä¸ªåŒºå—é“¾è·å¾—å¥–åŠ±çš„è¿‡ç¨‹ã€‚**å…±è¯†(`consensus`)**æ˜¯æŒ‡åŒºå—é“¾å„ä¸ªèŠ‚ç‚¹å¯¹ä¸‹ä¸€ä¸ªåŒºå—çš„å†…å®¹å½¢æˆä¸€è‡´çš„è¿‡ç¨‹ã€‚åœ¨ä»¥å¤ªåŠä¸­, `miner`åŒ…å‘å¤–æä¾›æŒ–çŸ¿åŠŸèƒ½ï¼Œ`consensus`åŒ…å¯¹å¤–æä¾›å…±è¯†å¼•æ“æ¥å£ã€‚
+ åœ¨æ§åˆ¶å°è¾“å…¥çš„`mine.start()`å‘½ä»¤å…¥å£ä¸º`/eth/api`ä¸­ä¸‹é¢è¿™ä¸ªå‡½æ•°

```go
/* FuM:å‚æ•°å³æŒ–çŸ¿æ‰€éœ€åç¨‹æ•°é‡ */
func (api *PrivateMinerAPI) Start(threads *int) error {
	if threads == nil {
		return api.e.StartMining(runtime.NumCPU())
	}
	return api.e.StartMining(*threads)
}
```

`StartMining()`å‡½æ•°è®¾ç½®äº†æŒ–çŸ¿çº¿ç¨‹æ•°ï¼Œè¯»å–å¹¶åœ¨äº¤æ˜“æ± ä¸­è®¾ç½®`gasPrice`ï¼Œé…ç½®æœ¬åœ°çŸ¿å·¥åœ°å€ã€‚å¦‚æœé‡‡ç”¨çš„æ˜¯`clique`å…±è¯†å¼•æ“ï¼ˆ`PoA`ï¼‰ï¼Œåˆ™ä¼šå¯¹é’±åŒ…è´¦æˆ·ç­‰è¿›è¡Œåˆå§‹åŒ–ã€‚æœ€åå¯åŠ¨åç¨‹`s.miner.Start(eb)`ã€‚

```go
// StartMining starts the miner with the given number of CPU threads. If mining
// is already running, this method adjust the number of threads allowed to use
// and updates the minimum price required by the transaction pool.
func (s *Ethereum) StartMining(threads int) error {
	// Update the thread count within the consensus engine
	type threaded interface {
		SetThreads(threads int)
	}
	if th, ok := s.engine.(threaded); ok {
		log.Info("Updated mining threads", "threads", threads)
		if threads == 0 {
			threads = -1 // Disable the miner from within
		}
		th.SetThreads(threads)
	}
	// If the miner was not running, initialize it
	if !s.IsMining() {
		// Propagate the initial price point to the transaction pool
		s.lock.RLock()//
		price := s.gasPrice
		s.lock.RUnlock()
		s.txPool.SetGasPrice(price)

		// Configure the local mining address
		eb, err := s.Etherbase()
		if err != nil {
			log.Error("Cannot start mining without etherbase", "err", err)
			return fmt.Errorf("etherbase missing: %v", err)
		}
		if clique, ok := s.engine.(*clique.Clique); ok {
			wallet, err := s.accountManager.Find(accounts.Account{Address: eb})
			if wallet == nil || err != nil {
				log.Error("Etherbase account unavailable locally", "err", err)
				return fmt.Errorf("signer missing: %v", err)
			}
			clique.Authorize(eb, wallet.SignData)
		}
		// If mining is started, we can disable the transaction rejection mechanism
		// introduced to speed sync times.
		atomic.StoreUint32(&s.protocolManager.acceptTxs, 1)

		go s.miner.Start(eb)
	}
	return nil
}
```

`Start()`å‡½æ•°è®¾ç½®çŸ¿å·¥åœ°å€å‚æ•°åæ£€æŸ¥ç¯å¢ƒå¼€å§‹æŒ–çŸ¿ã€‚

```go
func (miner *Miner) Start(coinbase common.Address) {
	atomic.StoreInt32(&miner.shouldStart, 1)
	miner.SetEtherbase(coinbase)

	if atomic.LoadInt32(&miner.canStart) == 0 {
		log.Info("Network syncing, will start miner afterwards")
		return
	}
	miner.worker.start()
}
```

`miner.worker.start()`å‡½æ•°å‘ç®¡é“ä¸­ä¼ é€ç©ºç»“æ„ä½“ä½œä¸ºä¿¡å·è§¦å‘æŒ–çŸ¿æ“ä½œã€‚

```go
// start sets the running status as 1 and triggers new work submitting.
func (w *worker) start() {
   atomic.StoreInt32(&w.running, 1)
   w.startCh <- struct{}{}
}
```

### æŒ–çŸ¿

`miner`åŒ…ä¸»è¦ç”±`miner.go` `worker.go`ä¸¤ä¸ªæ–‡ä»¶ç»„æˆã€‚

- `Miner` è´Ÿè´£ä¸å¤–éƒ¨äº¤äº’å’Œé«˜å±‚æ¬¡çš„æŒ–çŸ¿æ§åˆ¶ã€‚
- `worker` è´Ÿè´£ä½å±‚æ¬¡çš„æŒ–çŸ¿æ§åˆ¶ã€‚

`miner.go`ä¸­å£°æ˜äº†`miner`å¯¹è±¡ï¼ŒåŒæ ·`worker.go`ä¸­å£°æ˜äº†`worker`å¯¹è±¡ï¼Œ`worker`æ˜¯`miner`ç»“æ„ä½“ä¸­çš„ä¸€é¡¹ï¼Œå±äºä»å±å…³ç³»ã€‚

### ç”Ÿå‘½å‘¨æœŸ

+ åœ¨`geth`æ§åˆ¶å°ç¼–è¯‘å¯åŠ¨æ—¶ï¼Œä¸€ä¸ª`miner`å¯¹è±¡åŠå…¶ä»å±çš„`worker`å¯¹è±¡å°±å·²ç»è¢«å£°æ˜ã€‚åŒæ—¶å¯åŠ¨æŒ–çŸ¿ç›¸å…³åç¨‹ç­‰å¾…æŒ–çŸ¿æŒ‡ä»¤ã€‚
+ åœ¨æ¥æ”¶åˆ°æŒ–çŸ¿æŒ‡ä»¤åï¼Œ`worker`å¼€å§‹æ‰§è¡ŒæŒ–çŸ¿çš„ä¸€äº›æ“ä½œã€‚

### ä»£ç åˆ†æ

#### `miner`çš„å®šä¹‰

```go
type Miner struct {
	mux      *event.TypeMux //äº‹ä»¶æ¥æ”¶å™¨
	worker   *worker //ä»å±çš„worker
	coinbase common.Address //çŸ¿å·¥åœ°å€
	eth      Backend 
	engine   consensus.Engine //å…±è¯†å¼•æ“
	exitCh   chan struct{} //é€€å‡ºé€šé“ï¼Œæ¥æ”¶åˆ°æŒ‡ä»¤åä¼šåœæ­¢æŒ–çŸ¿

	canStart    int32 // can start indicates whether we can start the mining operation
	shouldStart int32 // should start indicates whether we should start after sync
}
```

#### `worker`çš„å®šä¹‰

```go
type worker struct {
	config      *Config
	chainConfig *params.ChainConfig
	engine      consensus.Engine
	eth         Backend
	chain       *core.BlockChain

	// Feeds
	pendingLogsFeed event.Feed

	// Subscriptions
	mux          *event.TypeMux
	txsCh        chan core.NewTxsEvent
	txsSub       event.Subscription
	chainHeadCh  chan core.ChainHeadEvent
	chainHeadSub event.Subscription
	chainSideCh  chan core.ChainSideEvent
	chainSideSub event.Subscription

	// Channels
	newWorkCh          chan *newWorkReq
	taskCh             chan *task
	resultCh           chan *types.Block
	startCh            chan struct{}
	exitCh             chan struct{}
	resubmitIntervalCh chan time.Duration
	resubmitAdjustCh   chan *intervalAdjust

	current      *environment                 // An environment for current running cycle.
	localUncles  map[common.Hash]*types.Block // A set of side blocks generated locally as the possible uncle blocks.
	remoteUncles map[common.Hash]*types.Block // A set of side blocks as the possible uncle blocks.
	unconfirmed  *unconfirmedBlocks           // A set of locally mined blocks pending canonicalness confirmations.

	mu       sync.RWMutex // The lock used to protect the coinbase and extra fields
	coinbase common.Address
	extra    []byte

	pendingMu    sync.RWMutex
	pendingTasks map[common.Hash]*task

	snapshotMu    sync.RWMutex // The lock used to protect the block snapshot and state snapshot
	snapshotBlock *types.Block
	snapshotState *state.StateDB

	// atomic status counters
	running int32 // The indicator whether the consensus engine is running or not.
	newTxs  int32 // New arrival transaction count since last sealing work submitting.

	// External functions
	isLocalBlock func(block *types.Block) bool // Function used to determine whether the specified block is mined by local miner.

	// Test hooks
	newTaskHook  func(*task)                        // Method to call upon receiving a new sealing task.
	skipSealHook func(*task) bool                   // Method to decide whether skipping the sealing.
	fullTaskHook func()                             // Method to call before pushing the full sealing task.
	resubmitHook func(time.Duration, time.Duration) // Method to call upon updating resubmitting interval.
}
```

`worker`ä¸­ä¸»è¦å®šä¹‰äº†ä¸€äº›æŒ–çŸ¿çš„é…ç½®ï¼Œå£°æ˜ä¸€äº›é€šé“æ¥æ§åˆ¶æŒ–çŸ¿è¿›ç¨‹ï¼Œä»¥åå†è¯¦ç»†åˆ†æã€‚

`worker`çš„æ„é€ å‡½æ•°å¯¹`worker`è¿›è¡Œç¤ºä¾‹åŒ–å¹¶å¯åŠ¨å››ä¸ªç›¸å…³åç¨‹ï¼Œè¿™å››ä¸ªåç¨‹åœ¨æ§åˆ¶å°å¯åŠ¨æ—¶å°±å·²ç»å¯åŠ¨ã€‚

```go
/* FuM:ç”¨äºæ ¹æ®ç»™å®šå‚æ•°æ„å»º worker */
func newWorker(config *Config, chainConfig *params.ChainConfig, engine consensus.Engine, eth Backend, mux *event.TypeMux, isLocalBlock func(*types.Block) bool, init bool) *worker {
	worker := &worker{
		config:       config,
		chainConfig:  chainConfig,
		engine:       engine,
		eth:          eth,
		mux:          mux, /* FuM: å‘å¤–éƒ¨å‘å¸ƒå·²ç»æŒ–åˆ°æ–°Block*/
		chain:        eth.BlockChain(),
		isLocalBlock: isLocalBlock,
		/* FuM:ä»¥ä¸Šå‡ é¡¹å‡æ¥è‡ªMiner */
		localUncles:        make(map[common.Hash]*types.Block),
		remoteUncles:       make(map[common.Hash]*types.Block),
		unconfirmed:        newUnconfirmedBlocks(eth.BlockChain(), miningLogAtDepth),
		pendingTasks:       make(map[common.Hash]*task),
		txsCh:              make(chan core.NewTxsEvent, txChanSize), /* FuM: ä»åå°ethæ¥æ”¶æ–°çš„Blockçš„Channel*/
		chainHeadCh:        make(chan core.ChainHeadEvent, chainHeadChanSize),
		chainSideCh:        make(chan core.ChainSideEvent, chainSideChanSize),
		newWorkCh:          make(chan *newWorkReq),
		taskCh:             make(chan *task),
		resultCh:           make(chan *types.Block, resultQueueSize),
		exitCh:             make(chan struct{}),
		startCh:            make(chan struct{}, 1),
		resubmitIntervalCh: make(chan time.Duration),
		resubmitAdjustCh:   make(chan *intervalAdjust, resubmitAdjustChanSize),
	}
	// Subscribe NewTxsEvent for tx pool
	worker.txsSub = eth.TxPool().SubscribeNewTxsEvent(worker.txsCh)
	// Subscribe events for blockchain
	worker.chainHeadSub = eth.BlockChain().SubscribeChainHeadEvent(worker.chainHeadCh)
	worker.chainSideSub = eth.BlockChain().SubscribeChainSideEvent(worker.chainSideCh)

	// Sanitize recommit interval if the user-specified one is too short.
	recommit := worker.config.Recommit
	if recommit < minRecommitInterval {
		log.Warn("Sanitizing miner recommit interval", "provided", recommit, "updated", minRecommitInterval)
		recommit = minRecommitInterval
	}

	go worker.mainLoop()
	go worker.newWorkLoop(recommit)
	go worker.resultLoop()
	go worker.taskLoop()

	// Submit first work to initialize pending state.
	if init {
		worker.startCh <- struct{}{}
	}
	return worker
}
```

### æŒ–çŸ¿æµç¨‹

```go
// start sets the running status as 1 and triggers new work submitting.
func (w *worker) start() {
	atomic.StoreInt32(&w.running, 1)
	w.startCh <- struct{}{}
}
```

å½“å¼€å§‹æ¥æ”¶åˆ°æŒ–çŸ¿æŒ‡ä»¤åä¼šè§¦å‘æ­¤å‡½æ•°ï¼šä½¿ç”¨åŸå­æ“ä½œå°†è¿è¡ŒçŠ¶æ€è®¾ç½®ä¸º`1`ï¼Œç„¶åå‘`worker`çš„`startCh`é€šé“å†™å¦‚ä¸€ä¸ªç©ºç»“æ„ä½“ã€‚ä¹‹åï¼Œåç¨‹`worker.newWorkLoop()`ä¼šæ¥æ”¶åˆ°`startCh`çš„ç©ºç»“æ„ä½“ï¼Œçœ‹`worker.newWorkLoop()`ä»£ç 

```go
// newWorkLoop is a standalone goroutine to submit new mining work upon received events.
func (w *worker) newWorkLoop(recommit time.Duration) {
	var (
		interrupt   *int32
		minRecommit = recommit // minimal resubmit interval specified by user.
		timestamp   int64      // timestamp for each round of mining.
	)

	timer := time.NewTimer(0)
	<-timer.C // discard the initial tick

	// commit aborts in-flight transaction execution with given signal and resubmits a new one.
	commit := func(noempty bool, s int32) {
		if interrupt != nil {
			atomic.StoreInt32(interrupt, s)
		}
		interrupt = new(int32)
		w.newWorkCh <- &newWorkReq{interrupt: interrupt, noempty: noempty, timestamp: timestamp}
		timer.Reset(recommit)
		atomic.StoreInt32(&w.newTxs, 0)
	}
	// recalcRecommit recalculates the resubmitting interval upon feedback.
	recalcRecommit := func(target float64, inc bool) {
		var (
			prev = float64(recommit.Nanoseconds())
			next float64
		)
		if inc {
			next = prev*(1-intervalAdjustRatio) + intervalAdjustRatio*(target+intervalAdjustBias)
			// Recap if interval is larger than the maximum time interval
			if next > float64(maxRecommitInterval.Nanoseconds()) {
				next = float64(maxRecommitInterval.Nanoseconds())
			}
		} else {
			next = prev*(1-intervalAdjustRatio) + intervalAdjustRatio*(target-intervalAdjustBias)
			// Recap if interval is less than the user specified minimum
			if next < float64(minRecommit.Nanoseconds()) {
				next = float64(minRecommit.Nanoseconds())
			}
		}
		recommit = time.Duration(int64(next))
	}
	// clearPending cleans the stale pending tasks.
	clearPending := func(number uint64) {
		w.pendingMu.Lock()
		for h, t := range w.pendingTasks {
			if t.block.NumberU64()+staleThreshold <= number {
				delete(w.pendingTasks, h)
			}
		}
		w.pendingMu.Unlock()
	}

	for {
		select {
		case <-w.startCh:
			clearPending(w.chain.CurrentBlock().NumberU64())
			timestamp = time.Now().Unix()
			commit(false, commitInterruptNewHead)

		case head := <-w.chainHeadCh:
			clearPending(head.Block.NumberU64())
			timestamp = time.Now().Unix()
			commit(false, commitInterruptNewHead)

		case <-timer.C:
			// If mining is running resubmit a new work cycle periodically to pull in
			// higher priced transactions. Disable this overhead for pending blocks.
			if w.isRunning() && (w.chainConfig.Clique == nil || w.chainConfig.Clique.Period > 0) {
				// Short circuit if no new transaction arrives.
				if atomic.LoadInt32(&w.newTxs) == 0 {
					timer.Reset(recommit)
					continue
				}
				commit(true, commitInterruptResubmit)
			}

		case interval := <-w.resubmitIntervalCh:
			// Adjust resubmit interval explicitly by user.
			if interval < minRecommitInterval {
				log.Warn("Sanitizing miner recommit interval", "provided", interval, "updated", minRecommitInterval)
				interval = minRecommitInterval
			}
			log.Info("Miner recommit interval update", "from", minRecommit, "to", interval)
			minRecommit, recommit = interval, interval

			if w.resubmitHook != nil {
				w.resubmitHook(minRecommit, recommit)
			}

		case adjust := <-w.resubmitAdjustCh:
			// Adjust resubmit interval by feedback.
			if adjust.inc {
				before := recommit
				recalcRecommit(float64(recommit.Nanoseconds())/adjust.ratio, true)
				log.Trace("Increase miner recommit interval", "from", before, "to", recommit)
			} else {
				before := recommit
				recalcRecommit(float64(minRecommit.Nanoseconds()), false)
				log.Trace("Decrease miner recommit interval", "from", before, "to", recommit)
			}

			if w.resubmitHook != nil {
				w.resubmitHook(minRecommit, recommit)
			}

		case <-w.exitCh:
			return
		}
	}
}
```

54è¡Œä¹‹å‰è¿›è¡Œäº†ä¸€äº›å˜é‡å’Œå‡½æ•°çš„å£°æ˜ï¼Œä¹‹åè¿›å…¥`for`å¾ªç¯é˜»å¡ç­‰å¾…é€šé“æŒ‡ä»¤ã€‚åœ¨ä¸Šé¢åˆ†æä¸­`start()`å‡½æ•°å·²ç»å¾€`w.startCh`å†™å…¥æ•°æ®ï¼Œæ­¤æ—¶ä¸åœ¨é˜»å¡ï¼Œæ‰§è¡Œä¸‹é¢è¿™ä¸ª`case`

```go
case <-w.startCh:
			clearPending(w.chain.CurrentBlock().NumberU64())//æ¸…é™¤é™ˆæ—§çš„pendingä»»åŠ¡
			timestamp = time.Now().Unix()//æ‹¿åˆ°ç°åœ¨çš„unixæ—¶é—´æˆ³ä½œä¸ºæœ¬è½®æŒ–çŸ¿å¼€å§‹æ—¶é—´
			commit(false, commitInterruptNewHead)
```

`commit`ä½¿ç”¨ç»™å®šçš„ä¿¡å·ä¸­æ­¢æ­£åœ¨è¿›è¡Œçš„äº‹åŠ¡å¤„ç†ï¼Œç„¶åé‡æ–°æäº¤ä¸€ä¸ªæ–°çš„ä¿¡å·ã€‚

```go
	commit := func(noempty bool, s int32) {
		if interrupt != nil {
			atomic.StoreInt32(interrupt, s)
		}
		interrupt = new(int32)
		w.newWorkCh <- &newWorkReq{interrupt: interrupt, noempty: noempty, timestamp: timestamp}
		timer.Reset(recommit)
		atomic.StoreInt32(&w.newTxs, 0)
	}
```

ç¬¬å…­è¡Œå‘`worker`çš„`newWorkCh`ç®¡é“å†™å…¥æ–°ä»»åŠ¡æŒ‡ä»¤ï¼Œäºæ˜¯åç¨‹`mainLoop()`åœæ­¢é˜»å¡ï¼Œ`mainLoop()`éƒ¨åˆ†ä»£ç å¦‚ä¸‹

```go
func (w *worker) mainLoop() {
	defer w.txsSub.Unsubscribe()
	defer w.chainHeadSub.Unsubscribe()
	defer w.chainSideSub.Unsubscribe()

	for {
		select {
		/* FuM:åŒºå—é“¾ä¸­å·²ç»åŠ å…¥äº†ä¸€ä¸ªæ–°çš„åŒºå—ä½œä¸ºæ•´ä¸ªé“¾çš„é“¾å¤´ï¼Œè¿™æ—¶workerçš„å›åº”æ˜¯ç«‹å³å¼€å§‹å‡†å¤‡æŒ–æ˜ä¸‹ä¸€ä¸ªæ–°åŒºå— */
		case req := <-w.newWorkCh:
			w.commitNewWork(req.interrupt, req.noempty, req.timestamp) /* FuM: æŒ–çŸ¿å·¥ä½œ */
		/* FuM:åŒºå—é“¾ä¸­åŠ å…¥äº†ä¸€ä¸ªæ–°åŒºå—ä½œä¸ºå½“å‰é“¾å¤´çš„æ—æ”¯ï¼Œworkerä¼šæŠŠè¿™ä¸ªåŒºå—æ”¶çº³è¿›localUncles[]æˆ–remoteUncles[]ï¼Œä½œä¸ºä¸‹ä¸€ä¸ªæŒ–æ˜æ–°åŒºå—å¯èƒ½çš„Uncleä¹‹ä¸€ */
		case ev := <-w.chainSideCh:
		Â·Â·Â·
```

ç¬¬9è¡Œ`case`æ¥æ”¶åˆ°æ–°ä»»åŠ¡æŒ‡ä»¤ï¼Œå¼€å§‹æ‰§è¡Œ`w.commitNewWork(req.interrupt, req.noempty, req.timestamp)`æŒ–çŸ¿å·¥ä½œã€‚

```go
func (w *worker) commitNewWork(interrupt *int32, noempty bool, timestamp int64) {
	w.mu.RLock()
	defer w.mu.RUnlock()

	tstart := time.Now()
	parent := w.chain.CurrentBlock()

	if parent.Time() >= uint64(timestamp) {
		timestamp = int64(parent.Time() + 1)
	}
	// this will ensure we're not going off too far in the future
	if now := time.Now().Unix(); timestamp > now+1 {
		wait := time.Duration(timestamp-now) * time.Second
		log.Info("Mining too far in the future", "wait", common.PrettyDuration(wait))
		time.Sleep(wait)
	}

	num := parent.Number()
	/* FuM:åˆ›å»ºåŒºå—å¤´ */
	header := &types.Header{
		ParentHash: parent.Hash(),
		Number:     num.Add(num, common.Big1),
		GasLimit:   core.CalcGasLimit(parent, w.config.GasFloor, w.config.GasCeil),
		Extra:      w.extra,
		Time:       uint64(timestamp),
	}
	// Only set the coinbase if our consensus engine is running (avoid spurious block rewards)
	if w.isRunning() {
		if w.coinbase == (common.Address{}) {
			log.Error("Refusing to mine without etherbase")
			return
		}
		header.Coinbase = w.coinbase
	}
	if err := w.engine.Prepare(w.chain, header); err != nil {
		log.Error("Failed to prepare header for mining", "err", err)
		return
	}
	// If we are care about TheDAO hard-fork check whether to override the extra-data or not
	/* FuM: æ˜¯å¦æ”¯æŒDAOäº‹ä»¶ç¡¬åˆ†å‰*/
	if daoBlock := w.chainConfig.DAOForkBlock; daoBlock != nil {
		// Check whether the block is among the fork extra-override range
		limit := new(big.Int).Add(daoBlock, params.DAOForkExtraRange)
		if header.Number.Cmp(daoBlock) >= 0 && header.Number.Cmp(limit) < 0 {
			// Depending whether we support or oppose the fork, override differently
			if w.chainConfig.DAOForkSupport {
				header.Extra = common.CopyBytes(params.DAOForkBlockExtra)
			} else if bytes.Equal(header.Extra, params.DAOForkBlockExtra) {
				header.Extra = []byte{} // If miner opposes, don't let it use the reserved extra-data
			}
		}
	}
	// Could potentially happen if starting to mine in an odd state.
	err := w.makeCurrent(parent, header)
	if err != nil {
		log.Error("Failed to create mining context", "err", err)
		return
	}
	// Create the current work task and check any fork transitions needed
	env := w.current
	if w.chainConfig.DAOForkSupport && w.chainConfig.DAOForkBlock != nil && w.chainConfig.DAOForkBlock.Cmp(header.Number) == 0 {
		misc.ApplyDAOHardFork(env.state)
	}
	// Accumulate the uncles for the current block
	uncles := make([]*types.Header, 0, 2)
	commitUncles := func(blocks map[common.Hash]*types.Block) {
		// Clean up stale uncle blocks first
		/* FuM: åˆ é™¤æ—§å—*/
		for hash, uncle := range blocks {
			if uncle.NumberU64()+staleThreshold <= header.Number.Uint64() {
				delete(blocks, hash)
			}
		}
		for hash, uncle := range blocks {
			if len(uncles) == 2 {
				break
			}
			/* FuM: æ ¡éªŒä¸€äº›å‚æ•°ï¼Œæäº¤å”å—*/
			if err := w.commitUncle(env, uncle.Header()); err != nil {
				log.Trace("Possible uncle rejected", "hash", hash, "reason", err)
			} else {
				log.Debug("Committing new uncle to block", "hash", hash)
				uncles = append(uncles, uncle.Header())
			}
		}
	}
	// Prefer to locally generated uncle
	commitUncles(w.localUncles)
	commitUncles(w.remoteUncles)

	if !noempty {
		// Create an empty block based on temporary copied state for sealing in advance without waiting block
		// execution finished.
		/* FuM:æ ¹æ®ä¸´æ—¶å¤åˆ¶çŠ¶æ€åˆ›å»ºä¸€ä¸ªç©ºå—ï¼Œä»¥ä¾¿æå‰å°è£…ï¼Œè€Œæ— éœ€ç­‰å¾…å—æ‰§è¡Œå®Œæˆã€‚ */
		w.commit(uncles, nil, false, tstart)
	}
	//ä»äº¤æ˜“æ± ä¸­å–äº¤æ˜“
	// Fill the block with all available pending transactions.
	pending, err := w.eth.TxPool().Pending()
	if err != nil {
		log.Error("Failed to fetch pending transactions", "err", err)
		return
	}
	// Short circuit if there is no available pending transactions
	if len(pending) == 0 {
		w.updateSnapshot()
		return
	}
	// Split the pending transactions into locals and remotes
	localTxs, remoteTxs := make(map[common.Address]types.Transactions), pending
	for _, account := range w.eth.TxPool().Locals() {
		if txs := remoteTxs[account]; len(txs) > 0 {
			delete(remoteTxs, account)
			localTxs[account] = txs
		}
	}
  //å¯¹å–å‡ºçš„äº¤æ˜“é›†æ•´ç†å¹¶æ‰§è¡Œ
	if len(localTxs) > 0 {
		txs := types.NewTransactionsByPriceAndNonce(w.current.signer, localTxs)
		if w.commitTransactions(txs, w.coinbase, interrupt) {
			return
		}
	}
	if len(remoteTxs) > 0 {
		txs := types.NewTransactionsByPriceAndNonce(w.current.signer, remoteTxs)
		if w.commitTransactions(txs, w.coinbase, interrupt) {
			return
		}
	}
	w.commit(uncles, w.fullTaskHook, true, tstart)//å¼€å§‹å‡ºå—
}
```

æ­¤å‡½æ•°ä¸»è¦å¯¹å‡†å¤‡æ–°å‡ºçš„å—åˆ›å»ºå—ç¼–å·ï¼Œå¤„ç†åŒºå—å¤´ã€æ—¶é—´æˆ³ï¼ŒDAOäº‹ä»¶ç¡¬åˆ†å‰ä»¥åŠå”å—ï¼Œå¦å¤–ï¼Œå–å‡ºæœ¬åœ°å’Œè¿œç¨‹äº¤æ˜“å¹¶æ‰§è¡Œã€‚å¤„ç†å®Œæ¯•åï¼Œç¬¬95è¡Œ`w.commit(uncles, nil, false, tstart)`å¼€å§‹å‡ºå—ã€‚ä¸‹é¢å…ˆä»‹ç»ä¸€ä¸‹äº¤æ˜“æ‰§è¡Œè¿‡ç¨‹ç¬¬120å’Œ126è¡Œ`w.commitTransactions(txs, w.coinbase, interrupt)`ã€‚`commitTransactions()`å‡½æ•°å¦‚ä¸‹

```go
/* FuM:æ‰§è¡Œäº¤æ˜“*/
func (w *worker) commitTransactions(txs *types.TransactionsByPriceAndNonce, coinbase common.Address, interrupt *int32) bool {
	// Short circuit if current is nil
	if w.current == nil {
		return true
	}

	if w.current.gasPool == nil {
		w.current.gasPool = new(core.GasPool).AddGas(w.current.header.GasLimit)
	}

	var coalescedLogs []*types.Log

	for {
		// In the following three cases, we will interrupt the execution of the transaction.
		// (1) new head block event arrival, the interrupt signal is 1
		// (2) worker start or restart, the interrupt signal is 1
		// (3) worker recreate the mining block with any newly arrived transactions, the interrupt signal is 2.
		// For the first two cases, the semi-finished work will be discarded.
		// For the third case, the semi-finished work will be submitted to the consensus engine.
		if interrupt != nil && atomic.LoadInt32(interrupt) != commitInterruptNone {
			// Notify resubmit loop to increase resubmitting interval due to too frequent commits.
			if atomic.LoadInt32(interrupt) == commitInterruptResubmit {
				ratio := float64(w.current.header.GasLimit-w.current.gasPool.Gas()) / float64(w.current.header.GasLimit)
				if ratio < 0.1 {
					ratio = 0.1
				}
				w.resubmitAdjustCh <- &intervalAdjust{
					ratio: ratio,
					inc:   true,
				}
			}
			return atomic.LoadInt32(interrupt) == commitInterruptNewHead
		}
		// If we don't have enough gas for any further transactions then we're done
		if w.current.gasPool.Gas() < params.TxGas {
			log.Trace("Not enough gas for further transactions", "have", w.current.gasPool, "want", params.TxGas)
			break
		}
		// Retrieve the next transaction and abort if all done
		tx := txs.Peek()
		if tx == nil {
			break
		}
		// Error may be ignored here. The error has already been checked
		// during transaction acceptance is the transaction pool.
		//
		// We use the eip155 signer regardless of the current hf.
		from, _ := types.Sender(w.current.signer, tx)
		// Check whether the tx is replay protected. If we're not in the EIP155 hf
		// phase, start ignoring the sender until we do.
		if tx.Protected() && !w.chainConfig.IsEIP155(w.current.header.Number) {
			log.Trace("Ignoring reply protected transaction", "hash", tx.Hash(), "eip155", w.chainConfig.EIP155Block)

			txs.Pop()
			continue
		}
		// Start executing the transaction
		w.current.state.Prepare(tx.Hash(), common.Hash{}, w.current.tcount)

		logs, err := w.commitTransaction(tx, coinbase)
		switch err {
		case core.ErrGasLimitReached:
			// Pop the current out-of-gas transaction without shifting in the next from the account
			log.Trace("Gas limit exceeded for current block", "sender", from)
			txs.Pop()

		case core.ErrNonceTooLow:
			// New head notification data race between the transaction pool and miner, shift
			log.Trace("Skipping transaction with low nonce", "sender", from, "nonce", tx.Nonce())
			txs.Shift()

		case core.ErrNonceTooHigh:
			// Reorg notification data race between the transaction pool and miner, skip account =
			log.Trace("Skipping account with hight nonce", "sender", from, "nonce", tx.Nonce())
			txs.Pop()

		case nil:
			// Everything ok, collect the logs and shift in the next transaction from the same account
			coalescedLogs = append(coalescedLogs, logs...)
			w.current.tcount++
			txs.Shift()

		default:
			// Strange error, discard the transaction and get the next in line (note, the
			// nonce-too-high clause will prevent us from executing in vain).
			log.Debug("Transaction failed, account skipped", "hash", tx.Hash(), "err", err)
			txs.Shift()
		}
	}

	if !w.isRunning() && len(coalescedLogs) > 0 {
		// We don't push the pendingLogsEvent while we are mining. The reason is that
		// when we are mining, the worker will regenerate a mining block every 3 seconds.
		// In order to avoid pushing the repeated pendingLog, we disable the pending log pushing.

		// make a copy, the state caches the logs and these logs get "upgraded" from pending to mined
		// logs by filling in the block hash when the block was mined by the local miner. This can
		// cause a race condition if a log was "upgraded" before the PendingLogsEvent is processed.
		cpy := make([]*types.Log, len(coalescedLogs))
		for i, l := range coalescedLogs {
			cpy[i] = new(types.Log)
			*cpy[i] = *l
		}
		w.pendingLogsFeed.Send(cpy)
	}
	// Notify resubmit loop to decrease resubmitting interval if current interval is larger
	// than the user-specified one.
	if interrupt != nil {
		w.resubmitAdjustCh <- &intervalAdjust{inc: false}
	}
	return false
}
```

æ­¤å‡½æ•°å¯¹äº¤æ˜“æ‰§è¡Œç¯å¢ƒè¿›è¡Œäº†ä¸€äº›æ£€æŸ¥ï¼Œç„¶åè¿›å…¥forå¾ªç¯å¯¹äº¤æ˜“ä¾æ¬¡æ‰§è¡Œï¼Œç¬¬61è¡Œ`logs, err := w.commitTransaction(tx, coinbase)`æ‰§è¡Œäº†ä¸€ä¸ªäº¤æ˜“ï¼Œä¸‹é¢æˆ‘ä»¬çœ‹`commitTransaction()`å‡½æ•°ã€‚

```go
//æ­¤å‡½æ•°æ‰§è¡Œå•ä¸ªäº¤æ˜“
func (w *worker) commitTransaction(tx *types.Transaction, coinbase common.Address) ([]*types.Log, error) {
   snap := w.current.state.Snapshot()

   receipt, err := core.ApplyTransaction(w.chainConfig, w.chain, &coinbase, w.current.gasPool, w.current.state, w.current.header, tx, &w.current.header.GasUsed, *w.chain.GetVMConfig())
   if err != nil {
      w.current.state.RevertToSnapshot(snap)
      return nil, err
   }
   w.current.txs = append(w.current.txs, tx)
   w.current.receipts = append(w.current.receipts, receipt)

   return receipt.Logs, nil
}
```

æ­¤å‡½æ•°å…ˆåˆ›å»ºçŠ¶æ€æ ‘å¿«ç…§ã€‚ç„¶åè¿è¡Œ`  receipt, err := core.ApplyTransaction(w.chainConfig, w.chain, &coinbase, w.current.gasPool, w.current.state, w.current.header, tx, &w.current.header.GasUsed, *w.chain.GetVMConfig())`ã€‚`ApplyTransaction()`å‡½æ•°è¿›è¡Œå…·ä½“çš„äº¤æ˜“æ‰§è¡Œï¼ˆåŒ…æ‹¬è½¬è´¦å’Œæ™ºèƒ½åˆçº¦çš„ç›¸å…³åŠ¨ä½œï¼‰ï¼Œäº¤ä»˜gasï¼Œè¿™é‡Œçš„gasåŒ…æ‹¬æ”¯ä»˜ç»™çŸ¿å·¥çš„gaså’ŒrefundGasã€‚`ApplyTransaction()`å‡½æ•°è¿”å›æ‹¿åˆ°æ”¶æ®`receipt`ï¼Œå¦‚æœæ‰§è¡Œå‡ºé”™å°±å°†çŠ¶æ€æ ‘å›æ»šè‡³åˆšæ‰åˆ›å»ºçš„å¿«ç…§ã€‚æ‰§è¡ŒæˆåŠŸä¹‹åè®°å½•æ­¤å·²æ‰§è¡Œäº¤æ˜“åŠå…¶æ”¶æ®ï¼Œå¹¶è¿”å›`receipt.Logs`ã€‚äº¤æ˜“æ‰§è¡Œå®Œåï¼Œæ‰§è¡Œ`w.commit(uncles, nil, false, tstart)`å¼€å§‹å‡ºå—ï¼Œä»£ç å¦‚ä¸‹ã€‚

```go
// commit runs any post-transaction state modifications, assembles the final block
// and commits new work if consensus engine is running.
func (w *worker) commit(uncles []*types.Header, interval func(), update bool, start time.Time) error {
	// Deep copy receipts here to avoid interaction between different tasks.
	receipts := make([]*types.Receipt, len(w.current.receipts))
	for i, l := range w.current.receipts {
		receipts[i] = new(types.Receipt)
		*receipts[i] = *l
	}
	s := w.current.state.Copy()
	block, err := w.engine.FinalizeAndAssemble(w.chain, w.current.header, s, w.current.txs, uncles, w.current.receipts)
	if err != nil {
		return err
	}
	if w.isRunning() {
		if interval != nil {
			interval()
		}
		select {
		case w.taskCh <- &task{receipts: receipts, state: s, block: block, createdAt: time.Now()}:
			w.unconfirmed.Shift(block.NumberU64() - 1)

			feesWei := new(big.Int)
			for i, tx := range block.Transactions() {
				feesWei.Add(feesWei, new(big.Int).Mul(new(big.Int).SetUint64(receipts[i].GasUsed), tx.GasPrice()))
			}
			feesEth := new(big.Float).Quo(new(big.Float).SetInt(feesWei), new(big.Float).SetInt(big.NewInt(params.Ether)))

			log.Info("Commit new mining work", "number", block.Number(), "sealhash", w.engine.SealHash(block.Header()),
				"uncles", len(uncles), "txs", w.current.tcount, "gas", block.GasUsed(), "fees", feesEth, "elapsed", common.PrettyDuration(time.Since(start)))

		case <-w.exitCh:
			log.Info("Worker has exited")
		}
	}
	if update {
		w.updateSnapshot()
	}
	return nil
}
```

æ­¤å‡½æ•°é¦–å…ˆæ·±æ‹·è´æ”¶æ®ï¼Œä»¥é¿å…ä¸åŒä»»åŠ¡ä¹‹é—´çš„äº¤äº’ã€‚æ„å»ºçŠ¶æ€æ ‘ `w.current.state` çš„å‰¯æœ¬`s`ã€‚**è°ƒç”¨å…±è¯†å¼•æ“çš„æ–¹æ³• `FinalizeAndAssemble() `ï¼Œæ ¹æ®å½“å‰é“¾çš„çŠ¶æ€é…ç½®æ–°å—çš„ä¸€äº›å‚æ•°ï¼Œç´¯ç§¯åŒºå—å’Œå”å—çš„å¥–åŠ±ï¼Œè®¾ç½®æœ€ç»ˆçŠ¶æ€å¹¶ç»„è£…åŒºå—å¾—åˆ°blockã€‚**ä¹‹åè¿è¡Œå¯èƒ½å­˜åœ¨çš„ä¸­æ–­å‡½æ•°(ç¬¬17è¡Œ)ã€‚

ç¬¬20è¡Œçš„`case`ä¸€å®šæ‰§è¡Œï¼Œè€Œæ ¹æ®`Go`è¯­è¨€çš„`select`è§„åˆ™ï¼ˆæ‰€æœ‰`channel`è¡¨è¾¾å¼éƒ½ä¼šè¢«æ±‚å€¼ã€æ‰€æœ‰è¢«å‘é€çš„è¡¨è¾¾å¼éƒ½ä¼šè¢«æ±‚å€¼ã€‚æ±‚å€¼é¡ºåºï¼šè‡ªä¸Šè€Œä¸‹ã€ä»å·¦åˆ°å³ï¼‰ï¼Œä¸‹é¢çš„`case <-w.exitCh`ä¼šåœ¨ä¸Šä¸€ä¸ª`case`æ‰§è¡Œå®Œä¹‹åå°è¯•æ¥æ”¶æ•°æ®ã€‚ä¸‹é¢ä¸»è¦çœ‹æŒ–çŸ¿çš„`case`ï¼Œä¹Ÿå°±æ˜¯ç¬¬20è¡Œçš„`case`æ‰§è¡Œæƒ…å†µï¼Œå¦‚ä¸‹ä»£ç ï¼š

```go
case w.taskCh <- &task{receipts: receipts, state: s, block: block, createdAt: time.Now()}:
			w.unconfirmed.Shift(block.NumberU64() - 1)//åˆ é™¤å¾…ç¡®è®¤åŒºå—åˆ—è¡¨ä¸­çš„è¿‡æœŸåŒºå—

			feesWei := new(big.Int)
			for i, tx := range block.Transactions() {
        //ç´¯è®¡åŒºå— block ä¸­æ‰€æœ‰äº¤æ˜“æ¶ˆè€— Gas çš„æ€»å’Œ feesWeiã€‚æ²¡æœ‰äº¤æ˜“å°±ä¸ç´¯è®¡ã€‚
				feesWei.Add(feesWei, new(big.Int).Mul(new(big.Int).SetUint64(receipts[i].GasUsed), tx.GasPrice()))
			}
			feesEth := new(big.Float).Quo(new(big.Float).SetInt(feesWei), new(big.Float).SetInt(big.NewInt(params.Ether)))//å°† feesWei è½¬æ¢æˆ feesEthï¼Œå³æ¶ˆè€—çš„æ€»ä»¥å¤ªå¸

			log.Info("Commit new mining work", "number", block.Number(), "sealhash", w.engine.SealHash(block.Header()),
				"uncles", len(uncles), "txs", w.current.tcount, "gas", block.GasUsed(), "fees", feesEth, "elapsed", common.PrettyDuration(time.Since(start)))
```

ä¸Šè¿°ä»£ç ä¾æ¬¡æ‰§è¡Œäº†ä»¥ä¸‹å‡ é¡¹å·¥ä½œï¼š

+ æ„å»ºä»»åŠ¡ `task`ï¼Œå¹¶å°†å…¶å‘é€åˆ°é€šé“ `taskCh`ï¼Œä»è€Œé©±åŠ¨åç¨‹ `worker.taskLoop()`çš„å·¥ä½œæµç¨‹ï¼Œåªæœ‰å½“è¿™ä¸ªcaseæ‰§è¡Œå®Œä¹‹åï¼Œåç¨‹ `worker.taskLoop()`ä¸­çš„`case task := <-w.taskCh`æ‰ä¼šè¢«æ±‚å€¼å¹¶å·¥ä½œ
+ åˆ é™¤å¾…ç¡®è®¤åŒºå—åˆ—è¡¨ä¸­çš„è¿‡æœŸåŒºå—
+ è®¡ç®—åŒºå—ä¸­äº¤æ˜“èŠ±è´¹çš„`Gas`
+ å°†` feesWei` è½¬æ¢æˆ `feesEth`ï¼Œå³æ¶ˆè€—çš„æ€»ä»¥å¤ªå¸
+ è‡³æ­¤ï¼Œå·²ç»æ‰“åŒ…å¥½äº†æœ€ç»ˆçš„å¾…ç­¾ååŒºå—ï¼Œè¾“å‡ºä¸€æ¡é‡è¦çš„æ—¥å¿—ä¿¡æ¯ã€‚

ä¸»è¦çœ‹ä¸‹ç¬¬11,12è¡Œ`log.Info`è¯­å¥

+ `block.Number()`æ˜¯å½“å‰åŒºå—æ•°
+ `w.engine.SealHash(block.Header())`å¯¹åŒºå—å¤´å†…å®¹è¿›è¡Œrlpç¼–ç åºåˆ—åŒ–å¹¶è¿”å›å…¶å“ˆå¸Œ
+ `len(uncles)`ï¼Œ`w.current.tcount`ï¼Œ`block.GasUsed()`ï¼Œ`feesEth`ï¼Œ`common.PrettyDuration(time.Since(start)))`åˆ†åˆ«æ˜¯å”å—é•¿åº¦ï¼Œäº¤æ˜“æ•°é‡ï¼Œ`gas`èŠ±è´¹é‡ï¼Œä»¥å¤ªå¸æ¶ˆè€—é‡ï¼Œæ‰§è¡Œæ—¶é—´ã€‚

æ­¤æ—¶`w.commit(uncles, nil, false, tstart)`æ‰§è¡Œå®Œæ¯•ã€‚æ‹¿åˆ°æœ€ç»ˆçš„å¾…ç­¾ååŒºå—åï¼Œåç¨‹`worker.taskLoop()`ä¸­çš„`case task := <-w.taskCh`å¼€å§‹å·¥ä½œã€‚

```go
case task := <-w.taskCh:
			//Hookå‡½æ•°å¥½åƒæ˜¯ä»£ç æµ‹è¯•ç”¨çš„ï¼Œå¾…æ¢ç©¶
			if w.newTaskHook != nil {
				w.newTaskHook(task)
			}
			// Reject duplicate sealing work due to resubmitting.
			sealHash := w.engine.SealHash(task.block.Header())//è·å–åŒºå—åœ¨è¢«ç­¾åä¹‹å‰çš„å“ˆå¸Œå€¼
			if sealHash == prev {
				continue
			}
			// Interrupt previous sealing operation
			interrupt()
			stopCh, prev = make(chan struct{}), sealHash

			if w.skipSealHook != nil && w.skipSealHook(task) {
				continue
			}
			w.pendingMu.Lock()//è¯»å†™é”å®š
			w.pendingTasks[w.engine.SealHash(task.block.Header())] = task//æ„é€ map
			w.pendingMu.Unlock()
			//è°ƒç”¨çš„å…±è¯†å¼•æ“çš„å—å°è£…å‡½æ•°Sealæ¥æ‰§è¡Œå…·ä½“çš„æŒ–çŸ¿æ“ä½œã€‚
			if err := w.engine.Seal(w.chain, task.block, w.resultCh, stopCh); err != nil {
				log.Warn("Block sealing failed", "err", err)
			}
```

ä¸Šè¿°ä»£ç æ˜¯åç¨‹`worker.taskLoop()`ä¸­çš„`case task := <-w.taskCh`çš„ä»£ç ï¼Œä¸»è¦åšäº†ä¸¤ä»¶äº‹ï¼š

+ è·å–å¾…ç­¾ååŒºå—å“ˆå¸Œ
+ è°ƒç”¨çš„å…±è¯†å¼•æ“çš„å—å°è£…å‡½æ•°Sealæ¥æ‰§è¡Œå…·ä½“çš„æŒ–çŸ¿æ“ä½œ

ä¸‹é¢çœ‹`w.engine.Seal()`ä¸­åˆ°åº•åšäº†ä»€ä¹ˆã€‚ä»¥å¤ªåŠå…±è¯†ç®—æ³•æœ‰`ethash`å’Œ`clique`ä¸¤ç§ï¼Œæ‰€ä»¥å¯¹åº”ç€æœ‰ä¸¤ç§`Seal`æ–¹æ³•çš„å®ç°ã€‚`ethash`æ˜¯`PoW`å®ç°ï¼Œ`clique`æ˜¯`PoA`å®ç°ï¼Œæˆ‘ä»¬å…ˆçœ‹`ethash`çš„`Seal`æ–¹æ³•ã€‚

```go
// Seal implements consensus.Engine, attempting to find a nonce that satisfies
// the block's difficulty requirements.
func (ethash *Ethash) Seal(chain consensus.ChainReader, block *types.Block, results chan<- *types.Block, stop <-chan struct{}) error {
	// If we're running a fake PoW, simply return a 0 nonce immediately
	// fakeæ¨¡å¼ç«‹å³è¿”å›0ä½œä¸ºnonce
	if ethash.config.PowMode == ModeFake || ethash.config.PowMode == ModeFullFake {
		header := block.Header()
		header.Nonce, header.MixDigest = types.BlockNonce{}, common.Hash{}
		select {
		case results <- block.WithSeal(header):
		default:
			ethash.config.Log.Warn("Sealing result is not read by miner", "mode", "fake", "sealhash", ethash.SealHash(block.Header()))
		}
		return nil
	}
	// If we're running a shared PoW, delegate sealing to it
	// å…±äº«powçš„è¯ï¼Œåˆ™è½¬åˆ°å®ƒçš„å…±äº«å¯¹è±¡æ‰§è¡ŒSealæ“ä½œ
	if ethash.shared != nil {
		return ethash.shared.Seal(chain, block, results, stop)
	}
	// Create a runner and the multiple search threads it directs
	// åˆ›å»ºä¸€ä¸ªrunnerä»¥åŠå®ƒæŒ‡æŒ¥çš„å¤šé‡æœç´¢çº¿ç¨‹
	abort := make(chan struct{})

	ethash.lock.Lock()        // çº¿ç¨‹ä¸Šé”ï¼Œä¿è¯å†…å­˜çš„ç¼“å­˜ï¼ˆåŒ…å«æŒ–çŸ¿å­—æ®µï¼‰å®‰å…¨
	threads := ethash.threads // æŒ–çŸ¿çš„çº¿ç¨‹s
	// ethash.randä¸ºç©ºï¼Œåˆ™ä¸ºethashçš„å­—æ®µrandèµ‹å€¼
	if ethash.rand == nil {
		seed, err := crand.Int(crand.Reader, big.NewInt(math.MaxInt64)) // è·å¾—ç§å­
		if err != nil {
			// æ‰§è¡Œå¤±è´¥ï¼Œæœ‰æŠ¥é”™ï¼Œå…ˆè§£é”çº¿ç¨‹ï¼Œç¨‹åºä¸­æ­¢ï¼Œç›´æ¥è¿”å›æŠ¥é”™ä¿¡æ¯
			ethash.lock.Unlock()
			return err
		}
		ethash.rand = rand.New(rand.NewSource(seed.Int64())) // æ‰§è¡ŒæˆåŠŸï¼Œæ‹¿åˆ°åˆæ³•ç§å­seedï¼Œé€šè¿‡å…¶è·å¾—randå¯¹è±¡ï¼Œèµ‹å€¼ã€‚
	}
	ethash.lock.Unlock() // è§£é”
	if threads == 0 {
		// æŒ–çŸ¿çº¿ç¨‹ç¼–å·ä¸º0ï¼Œåˆ™é€šè¿‡æ–¹æ³•è¿”å›å½“å‰ç‰©ç†ä¸Šå¯ç”¨CPUç¼–å·
		threads = runtime.NumCPU()
	}
	if threads < 0 {
		// éæ³•ç»“æœï¼Œçº¿ç¨‹ç½®ä¸º0ï¼Œå…è®¸åœ¨æœ¬åœ°æˆ–è¿œç¨‹æ²¡æœ‰é¢å¤–é€»è¾‘çš„æƒ…å†µä¸‹ï¼Œå–æ¶ˆæœ¬åœ°æŒ–çŸ¿æ“ä½œ
		threads = 0 // Allows disabling local mining without extra logic around local/remote
	}
	// Push new work to remote sealer
	if ethash.remote != nil {
		ethash.remote.workCh <- &sealTask{block: block, results: results}
	}
	var (
		pend   sync.WaitGroup // åˆ›å»ºä¸€ä¸ªå€’è®¡æ—¶é”å¯¹è±¡
		locals = make(chan *types.Block)
	)
	for i := 0; i < threads; i++ {
		pend.Add(1)
		go func(id int, nonce uint64) { // æ ¸å¿ƒä»£ç é€šè¿‡é—­åŒ…å¤šçº¿ç¨‹æŠ€æœ¯æ¥æ‰§è¡Œã€‚
			defer pend.Done()
			ethash.mine(block, id, nonce, abort, locals) // Sealæ ¸å¿ƒå·¥ä½œ
		}(i, uint64(ethash.rand.Int63())) //é—­åŒ…ç¬¬äºŒä¸ªå‚æ•°è¡¨è¾¾å¼uint64(ethash.rand.Int63())é€šè¿‡ä¸Šé¢å‡†å¤‡å¥½çš„randå‡½æ•°éšæœºæ•°ç»“æœä½œä¸ºnonceå®å‚ä¼ å…¥æ–¹æ³•ä½“
	}
	// ç›´åˆ°sealæ“ä½œè¢«ä¸­æ­¢æˆ–è€…æ‰¾åˆ°äº†ä¸€ä¸ªnonceå€¼ï¼Œå¦åˆ™ä¸€ç›´ç­‰
	// Wait until sealing is terminated or a nonce is found
	go func() {
		var result *types.Block // å®šä¹‰ä¸€ä¸ªåŒºå—å¯¹è±¡resultï¼Œç”¨äºæ¥æ”¶æ“ä½œç»“æœå¹¶ä½œä¸ºè¿”å›å€¼è¿”å›ä¸Šä¸€å±‚
		select {
		case <-stop:
			// Outside abort, stop all miner threads
			// å¤–éƒ¨æ„å¤–ä¸­æ­¢ï¼Œåœæ­¢æ‰€æœ‰æŒ–çŸ¿çº¿ç¨‹
			close(abort)
		case result = <-locals:
			// One of the threads found a block, abort all others
			// å…¶ä¸­ä¸€ä¸ªçº¿ç¨‹æŒ–åˆ°æ­£ç¡®å—ï¼Œä¸­æ­¢å…¶ä»–æ‰€æœ‰çº¿ç¨‹
			select {
			case results <- result:
			default:
				ethash.config.Log.Warn("Sealing result is not read by miner", "mode", "local", "sealhash", ethash.SealHash(block.Header()))
			}
			close(abort)
		case <-ethash.update:
			// Thread count was changed on user request, restart
			// ethashå¯¹è±¡å‘ç”Ÿæ”¹å˜ï¼Œåœæ­¢å½“å‰æ‰€æœ‰æ“ä½œï¼Œé‡å¯å½“å‰æ–¹æ³•
			close(abort)
			if err := ethash.Seal(chain, block, results, stop); err != nil {
				ethash.config.Log.Error("Failed to restart sealing after update", "err", err)
			}
		}
		// Wait for all miners to terminate and return the block
		// ç­‰å¾…æ‰€æœ‰çŸ¿å·¥åœæ­¢æˆ–è€…è¿”å›ä¸€ä¸ªåŒºå—
		pend.Wait()
	}()
	return nil
}
```

å‡½æ•°çš„è¯¦ç»†æµç¨‹åœ¨ä»£ç æ³¨é‡Šä¸­ä½“ç°ï¼Œæ­¤å‡½æ•°ä¸»è¦åšäº†å¦‚ä¸‹å·¥ä½œï¼š

+ ä½¿ç”¨éšæœºæ•°è·å–ç§å­`seed`
+ é…ç½®çº¿ç¨‹å¼€å§‹æ‰§è¡Œå¯»æ‰¾`nonce`

å¯»æ‰¾`nonce`çš„å·¥ä½œä¸»è¦ç”±ä¸Šè¿°ä»£ç ç¬¬58è¡Œ`ethash.mine(block, id, nonce, abort, locals)`æ‰§è¡Œï¼Œå¯ä»¥çœ‹å‡º`Seal()`æ–¹æ³•æ˜¯å¯¹å¤–çš„ï¼Œè€Œ`mine()`æ–¹æ³•æ˜¯å†…éƒ¨æ–¹æ³•ã€‚

éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œ`Seal()`å‡½æ•°è°ƒç”¨`mine()`å‡½æ•°æ˜¯é€šè¿‡å¯åŠ¨åç¨‹çš„æ–¹å¼å¯åŠ¨ï¼Œæ‰€ä»¥åœ¨å¯åŠ¨åç¨‹ä¹‹å`Seal()`å¹¶ä¸ä¼šç­‰å¾…`mine()`çš„ç»“æœï¼Œè€Œæ˜¯æ‰§è¡Œå®Œæˆåç›´æ¥è¿”å›ã€‚è€Œ`mine()`å‡½æ•°ä¼šåœ¨æ‰§è¡Œå®Œæ¯•åé€šè¿‡ç®¡é“è¿”å›æ‰§è¡Œç»“æœã€‚

`ethash.mine()`å‡½æ•°å¦‚ä¸‹

```go
// mine is the actual proof-of-work miner that searches for a nonce starting from
// seed that results in correct final block difficulty.
// mineå‡½æ•°æ˜¯çœŸæ­£çš„powçŸ¿å·¥ï¼Œç”¨æ¥æœç´¢ä¸€ä¸ªnonceå€¼ï¼Œnonceå€¼å¼€å§‹äºseedå€¼ï¼Œseedå€¼æ˜¯èƒ½æœ€ç»ˆäº§ç”Ÿæ­£ç¡®çš„å¯åŒ¹é…å¯éªŒè¯çš„åŒºå—éš¾åº¦
func (ethash *Ethash) mine(block *types.Block, id int, seed uint64, abort chan struct{}, found chan *types.Block) {
	// Extract some data from the header
	// ä»åŒºå—å¤´ä¸­æå–å‡ºä¸€äº›æ•°æ®ï¼Œæ”¾åœ¨ä¸€ä¸ªå…¨å±€å˜é‡åŸŸä¸­
	var (
		header  = block.Header()
		hash    = ethash.SealHash(header).Bytes()
		target  = new(big.Int).Div(two256, header.Difficulty)
		number  = header.Number.Uint64()
		dataset = ethash.dataset(number, false)
	)
	// Start generating random nonces until we abort or find a good one
	// å¼€å§‹ç”Ÿæˆéšæœºnonceå€¼çŸ¥é“æˆ‘ä»¬ä¸­æ­¢æˆ–è€…æˆåŠŸæ‰¾åˆ°äº†ä¸€ä¸ªåˆé€‚çš„å€¼
	var (
		attempts = int64(0) // åˆå§‹åŒ–ä¸€ä¸ªå°è¯•æ¬¡æ•°çš„å˜é‡ï¼Œä¸‹é¢ä¼šåˆ©ç”¨è¯¥å˜é‡è€ä¸€äº›èŠ±æª
		nonce    = seed     // åˆå§‹åŒ–ä¸ºseedå€¼ï¼Œåé¢æ¯æ¬¡å°è¯•ä»¥åä¼šç´¯åŠ 
	)
	logger := ethash.config.Log.New("miner", id)
	logger.Trace("Started ethash search for new nonces", "seed", seed)
search:
	for {
		select {
		case <-abort:
			// Mining terminated, update stats and abort
			// ä¸­æ­¢å‘½ä»¤ã€‚æŒ–çŸ¿ä¸­æ­¢ï¼Œæ›´æ–°çŠ¶æ€ï¼Œä¸­æ­¢å½“å‰æ“ä½œï¼Œè¿”å›ç©º
			logger.Trace("Ethash nonce search aborted", "attempts", nonce-seed)
			ethash.hashrate.Mark(attempts)
			break search

		default:
			// We don't have to update hash rate on every nonce, so update after after 2^X nonces
			// æˆ‘ä»¬æ²¡å¿…è¦åœ¨æ¯ä¸€æ¬¡å°è¯•nonceå€¼çš„æ—¶å€™æ›´æ–°hashç‡ï¼Œå¯ä»¥åœ¨å°è¯•äº†2çš„Xæ¬¡æ–¹nonceå€¼ä»¥åå†æ›´æ–°å³å¯
			attempts++
			if (attempts % (1 << 15)) == 0 {
				// è¿™é‡Œæ˜¯å®šçš„2çš„15æ¬¡æ–¹
				ethash.hashrate.Mark(attempts) // æ»¡è¶³æ¡ä»¶äº†ä»¥åï¼Œè¦æ›´æ–°ethashçš„hashç‡å­—æ®µçš„çŠ¶æ€å€¼
				attempts = 0                   // é‡ç½®å°è¯•æ¬¡æ•°
			}
			// Compute the PoW value of this nonce
			// ä¸ºè¿™ä¸ªnonceå€¼è®¡ç®—powå€¼
			digest, result := hashimotoFull(dataset.dataset, hash, nonce)
			if new(big.Int).SetBytes(result).Cmp(target) <= 0 {
				// Correct nonce found, create a new header with it
				// æ‰¾åˆ°æ­£ç¡®nonceå€¼ï¼Œåˆ›å»ºä¸€ä¸ªåŸºäºå®ƒçš„æ–°çš„åŒºå—å¤´
				header = types.CopyHeader(header)
				header.Nonce = types.EncodeNonce(nonce)// å°†è¾“å…¥çš„æ•´å‹å€¼è½¬æ¢ä¸ºä¸€ä¸ªåŒºå—nonceå€¼
				header.MixDigest = common.BytesToHash(digest)// å°†å­—èŠ‚æ•°ç»„è½¬æ¢ä¸ºHashå¯¹è±¡

				// Seal and return a block (if still needed)
				// å°è£…è¿”å›ä¸€ä¸ªåŒºå—
				select {
				case found <- block.WithSeal(header):
					logger.Trace("Ethash nonce found and reported", "attempts", nonce-seed, "nonce", nonce)
				case <-abort:
					logger.Trace("Ethash nonce found but discarded", "attempts", nonce-seed, "nonce", nonce)
				}
				break search
			}
			// ç´¯åŠ nonce
			nonce++
		}
	}
	// Datasets are unmapped in a finalizer. Ensure that the dataset stays live
	// during sealing so it's not unmapped while being read.
	runtime.KeepAlive(dataset)
}
```

å‡½æ•°çš„è¯¦ç»†æµç¨‹åœ¨ä»£ç æ³¨é‡Šä¸­ä½“ç°ï¼Œæ­¤å‡½æ•°ä¸»è¦åšäº†å¦‚ä¸‹å·¥ä½œï¼š

+ å¯»æ‰¾`nonce`çš„æ“ä½œ
+ æ‰¾åˆ°`nonce`åé‡å»ºåŒºå—å¤´

è‡³äºå¦‚ä½•åˆ¤æ–­`nonce`å€¼æ˜¯å¦æ­£ç¡®ï¼Œç”±ç¬¬44è¡Œ`if`æ¡ä»¶è¯­å¥æ¥åˆ¤æ–­ï¼Œä»¥åå†æ·±å±‚æ¬¡æŒ–æ˜ã€‚

åŒºå—å°è£…åï¼Œåç¨‹`resultLoop()`å¼€å§‹æ‰§è¡Œã€‚

```go
// resultLoop is a standalone goroutine to handle sealing result submitting
// and flush relative data to the database.
func (w *worker) resultLoop() {
	for {
		select {
		case block := <-w.resultCh:
			// Short circuit when receiving empty result.
			if block == nil {
				continue
			}
			// Short circuit when receiving duplicate result caused by resubmitting.
			if w.chain.HasBlock(block.Hash(), block.NumberU64()) {
				continue
			}
			var (
				sealhash = w.engine.SealHash(block.Header())
				hash     = block.Hash()
			)
			w.pendingMu.RLock()
			task, exist := w.pendingTasks[sealhash]
			w.pendingMu.RUnlock()
			if !exist {
				log.Error("Block found but no relative pending task", "number", block.Number(), "sealhash", sealhash, "hash", hash)
				continue
			}
			// Different block could share same sealhash, deep copy here to prevent write-write conflict.
			var (
				receipts = make([]*types.Receipt, len(task.receipts))
				logs     []*types.Log
			)
      // å¤„ç†äº¤æ˜“ç”Ÿæˆæ”¶æ®
			for i, receipt := range task.receipts {
				// add block location fields
				receipt.BlockHash = hash
				receipt.BlockNumber = block.Number()
				receipt.TransactionIndex = uint(i)

				receipts[i] = new(types.Receipt)
				*receipts[i] = *receipt
				// Update the block hash in all logs since it is now available and not when the
				// receipt/log of individual transactions were created.
				for _, log := range receipt.Logs {
					log.BlockHash = hash
				}
				logs = append(logs, receipt.Logs...)
			}
			// Commit block and state to database.
			/* FuM:å°†åŒºå—å†™å…¥åˆ°åŒºå—é“¾ä¸­ */
			_, err := w.chain.WriteBlockWithState(block, receipts, logs, task.state, true)
			if err != nil {
				log.Error("Failed writing block to chain", "err", err)
				continue
			}
			log.Info("Successfully sealed new block", "number", block.Number(), "sealhash", sealhash, "hash", hash,
				"elapsed", common.PrettyDuration(time.Since(task.createdAt)))

			// Broadcast the block and announce chain insertion event
			/* FuM:å‘å…¶ä»–èŠ‚ç‚¹å¹¿æ’­åŒºå—*/
			w.mux.Post(core.NewMinedBlockEvent{Block: block})

			// Insert the block into the set of pending ones to resultLoop for confirmations
			w.unconfirmed.Insert(block.NumberU64(), block.Hash())

		case <-w.exitCh:
			return
		}
	}
}
```

ä¸Šè¿°`resultLoop()`çš„`case block := <-w.resultCh`ä¸»è¦æ‰§è¡Œäº†ä»¥ä¸‹å·¥ä½œï¼š

+ éªŒè¯åŒºå—åˆæ³•æ€§
+ ä¸ºäº¤æ˜“ç”Ÿæˆæ”¶æ®
+ å°†åŒºå—å†™å…¥åˆ°åŒºå—é“¾ä¸­å¹¶æç¤º`log`ä¿¡æ¯
+ å‘å…¶ä»–èŠ‚ç‚¹å¹¿æ’­åŒºå—
+ å°†è¯¥åŒºå—å†™å…¥å¾…éªŒè¯åŒºå—`unconfirmedBlock`ä¸­(ç¬¬64è¡Œ)

æ¥ä¸‹æ¥ä¼šé‡å¤æŒ–çŸ¿æµç¨‹ã€‚

ä¸€ä¸ªåŒºå—äº§ç”Ÿä¹‹åï¼Œå®ƒä¸æ˜¯ç«‹å³å¯ä¿¡çš„ï¼Œç½‘ç»œä¸Šçš„èŠ‚ç‚¹æ€»æ˜¯ç›¸ä¿¡æœ€é•¿çš„é“¾ï¼Œå½“ä¸€æ¡äº¤æ˜“è®°å½•è¢«æ‰“åŒ…è¿›ä¸€ä¸ªåŒºå—ä¹‹åï¼Œå°±æœ‰äº†ä¸€ä¸ªç¡®è®¤ï¼Œè€Œè¿™ä¸ªåŒºå—æ‰€åœ¨çš„é“¾åé¢è¢«å†åŠ å…¥ä¸€ä¸ªåŒºå—ï¼Œå°±æ˜¯ç¬¬äºŒä¸ªç¡®è®¤ï¼Œå¦‚æ­¤ä¸‹å»ï¼Œä¸€ä¸ªäº¤æ˜“æœ‰äº†7ä¸ªç¡®è®¤ï¼Œæˆ‘ä»¬å°±è®¤ä¸ºè¿™ä¸ªäº¤æ˜“å·²ç»ç¡®å®šäº†ï¼Œä¼šè¢«æ°¸è¿œè®°å½•åœ¨åŒºå—é“¾ä¸­ã€‚ä¸ºä»€ä¹ˆæ˜¯7ä¸ªç¡®è®¤å‘¢ï¼Ÿå› ä¸ºæ¯ä¸€ä¸ªç¡®è®¤å°±æ˜¯ä¸€ä¸ªæŒ–çŸ¿è¿‡ç¨‹ï¼Œéƒ½éœ€è¦æä¾›éå¸¸ä¸¥æ ¼çš„è®¡ç®—ï¼Œå› æ­¤ï¼Œè¿™7ä¸ªåŒºå—è¢«åŒä¸€ä¸ªçŸ¿å·¥åˆ›å»ºçš„å¯èƒ½æ€§å¾®ä¹å…¶å¾®ï¼ˆå¯ä»¥è¯´æ˜¯ä¸å¯èƒ½ï¼‰ï¼Œå› æ­¤çŸ¿å·¥ä¼ªé€ äº¤æ˜“ä¹ŸåŸºæœ¬ä¸å¯èƒ½ã€‚æ‰€ä»¥å½“æŒ–å‡ºç¬¬8ä¸ªå¾…ç¡®è®¤å—ï¼Œç¬¬ä¸€ä¸ªå¾…ç¡®è®¤å—ä¼šä¼šè¢«æ°¸è¿œè®°å½•åœ¨åŒºå—é“¾ä¸­ã€‚

ç›¸å…³`log`è¾“å‡º

```
ğŸ”¨ mined potential block //æŒ–å‡ºåŒºå—æ—¶
ğŸ”— block reached canonical chain//åŒºå—ç¡®è®¤å
â‘‚ block became an uncle //åŒºå—æˆä¸ºå”å—
ğŸ˜± block lost //åŒºå—ä¸¢å¤±
Failed to retrieve header of mined block//åŒºå—å¤´æ— æ³•æ£€ç´¢é”™è¯¯
```



## ç®—æ³•

ethashåŒ…ä¸­åŒ…å«å‡ ä¸ªalgorithmå¼€å¤´çš„æ–‡ä»¶ï¼Œè¿™äº›æ–‡ä»¶çš„å†…å®¹æ˜¯powæ ¸å¿ƒç®—æ³•ï¼Œç”¨æ¥æ”¯æŒæŒ–çŸ¿æ“ä½œã€‚

åœ¨å…±è¯†å¼•æ“çš„`mine()`å‡½æ•°ä¸­ï¼Œä¸‹é¢è¿™å¥è¯æ˜¯å¯»æ‰¾nonceçš„é‡ç‚¹

> ```go
> digest, result := hashimotoFull(dataset.dataset, hash, nonce)
> ```

###### hashimotoFullå‡½æ•°

```go
// åœ¨ä¼ å…¥çš„æ•°æ®é›†ä¸­é€šè¿‡hashå’Œnonceå€¼è®¡ç®—åŠ å¯†å€¼
func hashimotoFull(dataset []uint32, hash []byte, nonce uint64) ([]byte, []byte) {
    // æœ¬å‡½æ•°æ ¸å¿ƒä»£ç æ®µï¼šå®šä¹‰ä¸€ä¸ªlookupå‡½æ•°ï¼Œç”¨äºåœ¨æ•°æ®é›†ä¸­æŸ¥æ‰¾æ•°æ®
	lookup := func(index uint32) []uint32 {
		offset := index * hashWords // hashWordsæ˜¯å®šä¹‰çš„å¸¸é‡å€¼ =16
		return dataset[offset : offset+hashWords]
	}
	// hashimotoFullå‡½æ•°åšçš„å·¥ä½œå°±æ˜¯å°†åŸå§‹æ•°æ®é›†è¿›è¡Œäº†è¯»å–åˆ†å‰²ï¼Œç„¶åä¼ ç»™hashimotoå‡½æ•°ã€‚
	return hashimoto(hash, nonce, uint64(len(dataset))*4, lookup)
}
```

###### hashimotoå‡½æ•°

```go
// hashimoto aggregates data from the full dataset in order to produce our final
// value for a particular header hash and nonce.
func hashimoto(hash []byte, nonce uint64, size uint64, lookup func(index uint32) []uint32) ([]byte, []byte) {
	// Calculate the number of theoretical rows (we use one buffer nonetheless)
	rows := uint32(size / mixBytes)

	// Combine header+nonce into a 64 byte seed
	seed := make([]byte, 40)
	copy(seed, hash)
	binary.LittleEndian.PutUint64(seed[32:], nonce)

	seed = crypto.Keccak512(seed)
	seedHead := binary.LittleEndian.Uint32(seed)

	// Start the mix with replicated seed
	mix := make([]uint32, mixBytes/4)
	for i := 0; i < len(mix); i++ {
		mix[i] = binary.LittleEndian.Uint32(seed[i%16*4:])
	}
	// Mix in random dataset nodes
	temp := make([]uint32, len(mix))

	for i := 0; i < loopAccesses; i++ {
		parent := fnv(uint32(i)^seedHead, mix[i%len(mix)]) % rows
		for j := uint32(0); j < mixBytes/hashBytes; j++ {
			copy(temp[j*hashWords:], lookup(2*parent+j))
		}
		fnvHash(mix, temp)
	}
	// Compress mix
	for i := 0; i < len(mix); i += 4 {
		mix[i/4] = fnv(fnv(fnv(mix[i], mix[i+1]), mix[i+2]), mix[i+3])
	}
	mix = mix[:len(mix)/4]

	digest := make([]byte, common.HashLength)
	for i, val := range mix {
		binary.LittleEndian.PutUint32(digest[i*4:], val)
	}
	return digest, crypto.Keccak256(append(seed, digest...))
}
```

ä¸Šè¿°å‡½æ•°ä¸»è¦æ˜¯é€šè¿‡æ•°å­¦è®¡ç®—å¾—åˆ°`nonce`å¯¹åº”çš„åŠ å¯†å€¼`digest`ï¼Œ`digest, result := hashimotoFull(dataset.dataset, hash, nonce)`æ‹¿åˆ°`digest`å’Œ`result`ä¹‹åéœ€è¦éªŒè¯æ­¤åŠ å¯†å€¼ã€‚

> ```new(big.Int).SetBytes(result).Cmp(target) <= 0	```

éªŒè¯çš„æ–¹æ³•å¾ˆç®€å•ï¼Œåªæ˜¯ä½¿ç”¨`result`å’Œ`target`è¿›è¡Œæ¯”è¾ƒï¼Œå¦‚æœå°äºç­‰äº0å³ä¸ºé€šè¿‡ã€‚`target`æ˜¯åœ¨`mine`æ–¹æ³•ä½“ä¸­é å‰çš„å˜é‡å£°æ˜éƒ¨åˆ†

> target = new(big.Int).Div(maxUint256, header.Difficulty)

å¯ä»¥çœ‹å‡ºï¼Œ`target`çš„å®šä¹‰æ˜¯æ ¹æ®åŒºå—å¤´ä¸­çš„éš¾åº¦å€¼è¿ç®—è€Œå¾—å‡ºçš„ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒæ•´`Difficulty`å€¼ï¼Œæ¥æ§åˆ¶`pow`è¿ç®—éš¾åº¦ï¼Œç”Ÿæˆæ­£ç¡®`nonce`çš„éš¾åº¦ï¼Œè¾¾åˆ°`pow`å·¥ä½œé‡å¯æ§çš„ç›®æ ‡ã€‚